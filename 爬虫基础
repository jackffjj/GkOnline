1.1 URI和URL
URI的全称为Uniform Resource Identifier，即统一资源标志符，URL的全称为Universal Resource Locator，即统一资源定位符。
一般的网页链接我们既可以称为URL，也可以称为URI。
2.超文本：我们在浏览器里看到的网页就是超文本解析而成的，其网页源代码是一系列HTML代码，里面包含了一系列标签，比如img显示图片，p指定显示段落等。浏览器解析这些标签后，便形成了我们平常看到的网页，而网页的源代码HTML就可以称作超文本。
3.http，https
HTTP的全称是Hyper Text Transfer Protocol，中文名叫作超文本传输协议。HTTP协议是用于从网络传输超文本数据到本地浏览器的传送协议，它能保证高效而准确地传送超文本文档。
HTTPS的安全基础是SSL，因此通过它传输的内容都是经过SSL加密的
4.http请求过程
这个过程是浏览器向网站所在的服务器发送了一个请求，网站服务器接收到这个请求后进行处理和解析，然后返回对应的响应，接着传回给浏览器。响应里包含了页面的源代码等内容，浏览器再对其进行解析，便将网页呈现了出来
5.
请求：由客户端向服务端发出，可以分为4部分内容：请求方法（Request Method）、请求的网址（Request URL）、请求头（Request Headers）、请求体（Request Body）。
get请求在一个浏览器中输入url回车就发送了一个get请求，请求参数直接包含在里面
POST请求大多在表单提交时发起。比如，对于一个登录表单，输入用户名和密码后，点击“登录”按钮，这通常会发起一个POST请求，其数据通常以表单的形式传输，而不会体现在URL中。
6.请求头：
请求头，用来说明服务器要使用的附加信息，比较重要的信息有Cookie、Referer、User-Agent等。下面简要说明一些常用的头信息。
Accept：请求报头域，用于指定客户端可接受哪些类型的信息。
Accept-Language：指定客户端可接受的语言类型。
Accept-Encoding：指定客户端可接受的内容编码。
Host：用于指定请求资源的主机IP和端口号，其内容为请求URL的原始服务器或网关的位置。从HTTP 1.1版本开始，请求必须包含此内容。
Cookie：也常用复数形式 Cookies，这是网站为了辨别用户进行会话跟踪而存储在用户本地的数据。它的主要功能是维持当前访问会话。例如，我们输入用户名和密码成功登录某个网站后，服务器会用会话保存登录状态信息，后面我们每次刷新或请求该站点的其他页面时，会发现都是登录状态，这就是Cookies的功劳。Cookies里有信息标识了我们所对应的服务器的会话，每次浏览器在请求该站点的页面时，都会在请求头中加上Cookies并将其发送给服务器，服务器通过Cookies识别出是我们自己，并且查出当前状态是登录状态，所以返回结果就是登录之后才能看到的网页内容。
Referer：此内容用来标识这个请求是从哪个页面发过来的，服务器可以拿到这一信息并做相应的处理，如作来源统计、防盗链处理等。
User-Agent：简称UA，它是一个特殊的字符串头，可以使服务器识别客户使用的操作系统及版本、浏览器及版本等信息。在做爬虫时加上此信息，可以伪装为浏览器；如果不加，很可能会被识别出为爬虫。
Content-Type：也叫互联网媒体类型（Internet Media Type）或者MIME类型，在HTTP协议消息头中，它用来表示具体请求中的媒体类型信息。例如，text/html代表HTML格式，image/gif代表GIF图片，application/json代表JSON类型，更多对应关系可以查看此对照表：http://tool.oschina.net/commons。
因此，请求头是请求的重要组成部分，在写爬虫时，大部分情况下都需要设定请求头。
7.请求体
请求体一般承载的内容是POST请求中的表单数据，而对于GET请求，请求体则为空
此时需要注意Request Headers中指定Content-Type为application/x-www-form-urlencoded。只有设置Content-Type为application/x-www-form-urlencoded，才会以表单数据的形式提交。
8.响应
由服务端返回给客户端，可以分为三部分：响应状态码（Response Status Code）、响应头（Response Headers）和响应体（Response Body）。
9.
200 - 请求成功
301 - 资源（网页等）被永久转移到其它URL
404 - 请求的资源（网页等）不存在
500 - 内部服务器错误
10.响应体
最重要的当属响应体的内容了。响应的正文数据都在响应体中，比如请求网页时，它的响应体就是网页的HTML代码；请求一张图片时，它的响应体就是图片的二进制数据。我们做爬虫请求网页后，要解析的内容就是响应体。
在浏览器开发者工具中点击Preview，就可以看到网页的源代码，也就是响应体的内容，它是解析的目标。
在做爬虫时，我们主要通过响应体得到网页的源代码、JSON数据等，然后从中做相应内容的提取。
11.css选择器定位节点
在浏览器开发者工具中点击Preview，就可以看到网页的源代码，也就是响应体的内容，它是解析的目标。
在做爬虫时，我们主要通过响应体得到网页的源代码、JSON数据等，然后从中做相应内容的提取。
另外，CSS选择器还支持嵌套选择，各个选择器之间加上空格分隔开便可以代表嵌套关系，如#container .wrapper p则代表先选择id为container的节点，然后选中其内部的class为wrapper的节点，然后再进一步选中其内部的p节点。另外，如果不加空格，则代表并列关系，如div#container .wrapper p.text代表先选择id为container的div节点，然后选中其内部的class为wrapper的节点，再进一步选中其内部的class为text的p节点。这就是CSS选择器，其筛选功能还是非常强大的
12.爬虫基本原理（当有大量数据时，爬虫可以在抓取过程中进行各种异常处理、错误重试等操作，确保爬取持续高效地运行）
把网的节点比作一个个网页，爬虫爬到这就相当于访问了该页面，获取了其信息。可以把节点间的连线比作网页与网页之间的链接关系，这样蜘蛛通过一个节点后，可以顺着节点连线继续爬行到达下一个节点，即通过一个网页继续获取后续的网页，这样整个网的节点便可以被蜘蛛全部爬行到，网站的数据就可以被抓取下来了。
简单来说，爬虫就是获取网页并提取和保存信息的自动化程序
流程：
1.获取网页：爬虫首先要做的工作就是获取网页，这里就是获取网页的源代，最关键的部分就是构造一个请求并发送给服务器，然后接收到响应并将其解析出来
Python提供了许多库来帮助我们实现这个操作，如urllib、requests等。我们可以用这些库来帮助我们实现HTTP请求操作，请求和响应都可以用类库提供的数据结构来表示，得到响应之后只需要解析数据结构中的Body部分即可，即得到网页的源代码，这样我们可以用程序来实现获取网页的过程了。
2.提取数据
最通用的方法便是采用正则表达式提取，这是一个万能的方法，但是在构造正则表达式时比较复杂且容易出错。然而由于网页的结构有一定的规则，所以还有一些根据网页节点属性、CSS选择器或XPath来提取网页信息的库，如Beautiful Soup、pyquery、lxml等。使用这些库，我们可以高效快速地从中提取网页信息，如节点的属性、文本值等。
3.保存数据
提取信息后，我们一般会将提取到的数据保存到某处以便后续使用。这里保存形式有多种多样，如可以简单保存为TXT文本或JSON文本，也可以保存到数据库，如MySQL和MongoDB等，也可保存至远程服务器，如借助SFTP进行操作等。
13.如果是java渲染出来的页面，可能经过urllib，request这样的库抓取到的源代码可能和页面看的的源代码不一样，因为在浏览器中打开这个页面时，首先会加载这个HTML内容，接着浏览器会发现其中引入了一个js文件，然后便会接着去请求这个文件，获取到该文件后，便会执行其中的JavaScript代码，而JavaScript则会改变HTML中的节点，向其添加内容，最后得到完整的页面。
14.静态页面和动态页面
静态页面虽然加载速度快，编写简单，但是可维护性差，不能根据url灵活多变的显示内容，例如，我们想要给这个网页的URL传入一个name参数，让其在网页中显示出来，是无法做到的。
动态页面：可以动态解析url参数内容，关联数据库并动态显示页面内容
15.会话和cookie
a.当用户请求来自应用程序web页面，而用户还没有会话，服务器就会创建一个会话对象，会话对象用来存储特定用户会话所需的属性和配置信息，在用户进行应用程序web页面跳转的时候，会话对象的信息不会丢失，而是一直保持在会话中。会话过期或者被放弃的时候，服务器就会停止这个会话。
cookie是网站为了辨别用户，跟踪会话而保存在客户端本地的数据。
b.我们怎样利用Cookies保持状态呢，当用户第一次向服务器请求的时候，服务器会返回一个请求头带有set-cookie的字段的响应给浏览器，浏览器保存在本地，在下一次对页面的请求的时候，浏览器把这个cookie放在请求头发送给服务器，服务器再找到对应的会话加以判断。如果会话中的某些设置登录状态的变量是有效的，那就证明用户处于登录状态，此时返回登录之后才可以查看的网页内容，浏览器再进行解析便可以看到了。
c.
cookie的属性：
+ Name：该Cookie的名称。一旦创建，该名称便不可更改。
+ Value：该Cookie的值。如果值为Unicode字符，需要为字符编码。如果值为二进制数据，则需要使用BASE64编码。
+ Domain：可以访问该Cookie的域名。例如，如果设置为.zhihu.com，则所有以zhihu.com，结尾的域名都可以访问该Cookie。
+ Max Age：该Cookie失效的时间，单位为秒，也常和Expires一起使用，通过它可以计算出其有效时间。Max Age如果为正数，则该Cookie在Max Age秒之后失效。如果为负数，则关闭浏览器时Cookie即失效，浏览器也不会以任何形式保存该Cookie。
+ Path：该Cookie的使用路径。如果设置为/path/，则只有路径为/path/的页面可以访问该Cookie。如果设置为/，则本域名下的所有页面都可以访问该Cookie。
+ Size字段：此Cookie的大小。
+ HTTP字段：Cookie的httponly属性。若此属性为true，则只有在HTTP头中会带有此Cookie的信息，而不能通过document.cookie来访问此Cookie。
+ Secure：该Cookie是否仅被使用安全协议传输。安全协议有HTTPS和SSL等，在网络上传输数据之前先将数据加密。默认为false。
d.会话Cookie和持久Cookie
会话cookie保存在浏览器内存中，关闭浏览器cookie就失效了，持久cookie是保存在客户端硬盘，用于长久保持用户登录状态
严格来说没有会话cookie和持久cookie之分，只是设置了cookie的max age有效时间决定过期时间而已
16.反爬对应一：代理
我们正常的情况下是浏览器发送请求到服务器，服务器返回响应给浏览器，当用代理的时候，相当于在中间搭建了一个桥，浏览器发送请求给代理服务器，代理服务器发送给服务器，然后由代理服务器将服务器的响应转发给浏览器，这样子服务器就不会识别是本机的ip进行多次请求了

